{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPmWg2Ek9xrYfH6m74go0lD"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"Ykpyr-B3E3Co"},"outputs":[],"source":["pip install -U langchain-text-splitters"]},{"cell_type":"code","source":["pip install chromadb"],"metadata":{"id":"oYNRyvCpFN3o"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/movies_metadata.csv')\n","df.head()"],"metadata":{"id":"dGkr5kSdFO8P"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sentence_transformers import SentenceTransformer\n","from langchain_text_splitters import NLTKTextSplitter\n","import chromadb"],"metadata":{"id":"bzY-195hFO5R"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import nltk\n","nltk.download('punkt_tab')"],"metadata":{"id":"iqZc5m7LFO2p"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df = df[['original_title','overview']]"],"metadata":{"id":"4e25FAFqFOz4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["text_splitter = NLTKTextSplitter(chunk_size=1500)"],"metadata":{"id":"ltaYBAY4FOxA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def split_overview(overview):\n","  if pd.isna(overview):\n","    return []\n","  return text_splitter.split_text(str(overview))"],"metadata":{"id":"H5h77120FOtR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df['chunks'] = df['overview'].apply(split_overview)"],"metadata":{"id":"wrJb6FhMFOqI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["chunked_df = df.explode('chunks').reset_index(drop=True)"],"metadata":{"id":"53X987z9FOjg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["embedder = SentenceTransformer('all-MiniLM-L6-v2')"],"metadata":{"id":"FzpKbzOMFOgo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def encode_chunk(chunk):\n","  if not isinstance(chunk, str) or chunk.strip() == \"\":\n","    return None\n","  return embedder.encode(chunk).tolist()"],"metadata":{"id":"Y8FcN6ZNFOd5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["chunked_df['embeddings'] = chunked_df['chunks'].apply(encode_chunk)"],"metadata":{"id":"XIywcAJ_FObB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["chunked_df.dropna(subset=['embeddings'], inplace=True)"],"metadata":{"id":"LrLTGUr_FOYY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["client = chromadb.Client()\n","collection = client.create_collection(name='movies')"],"metadata":{"id":"AOxyrtA7Fq2b"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for idx, row in chunked_df.iterrows():\n","  collection.add(\n","      ids = [str(idx)],\n","      embeddings=[row['embeddings']],\n","      metadatas=[{\n","          'original_title': row['original_title'],\n","          'chunk': row['chunks']\n","      }]\n","  )\n","  print(\"Data successfully stored in ChromaDB.\")"],"metadata":{"id":"q-kWEZmCFqzx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n","from chromadb import Client\n","import torch"],"metadata":{"id":"dp0p8_hrFqxP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sentence_model = SentenceTransformer('all-MiniLM-L6-v2')"],"metadata":{"id":"Qn1rSX4jFquR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tokenizer = AutoTokenizer.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.1\")"],"metadata":{"id":"Yfbfdj3pFqrg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = AutoModelForCausalLM.from_pretrained(\n","    \"mistralai/Mistral-7B-Instruct-v0.1\",\n","    device_map='auto'\n",")"],"metadata":{"id":"jm72qVnXFqox"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["text_generation_pipeline = pipeline(\n","    model=model,\n","    tokenizer=tokenizer,\n","    task='text-generation',\n","    return_full_text=True,\n","    max_new_tokens=800\n",")"],"metadata":{"id":"MCwUnMAAFqkw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def retrieve_documents(query, collection, top_k=5):\n","\n","  query_embedding = sentence_model.encode(query).tolist()\n","\n","  results = collection.query(\n","      query_embeddings = [query_embedding],\n","      n_results=top_k\n","  )\n","\n","  if not results['documents']:\n","    print(\"No results found for the query.\")\n","    return [], []\n","\n","  chunks = []\n","  titles = []\n","  for document in results['metadatas'][0]:\n","    chunks.append(document['chunk'])\n","    titles.append(document['original_title'])\n","    return chunks, titles"],"metadata":{"id":"SIT7rK6SFqev"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def generate_answer(query, chunks, titles, text_generation_pipeline):\n","    # Prepare the context from chunks and titles\n","    context = \"\\n\\n\".join([f\"Title: {title}\\nChunk: {chunk}\" for title,\n","                           chunk in zip(titles, chunks)])\n","\n","    # Prepare the prompt\n","    prompt = f\"\"\"[INST]\n","    Instruction: You're an expert in movie suggestions. Your task is to analyze carefully the context and come up with an exhaustive answer to the following question:\n","    {query}\n","\n","    Here is the context to help you:\n","\n","    {context}\n","\n","    [/INST]\"\"\"\n","\n","    # Generate the answer using the model\n","    generated_text = text_generation_pipeline(prompt)[0]['generated_text']\n","\n","    return generated_text"],"metadata":{"id":"6rvm6dypFqcQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["client = chromadb.Client()\n","collection = client.get_collection(name='movies')\n","\n","query = \"What are some good movies to watch on a rainy day?\"\n","top_k = 5\n","\n","# Retrieve documents\n","chunks, titles = retrieve_documents(query, collection, top_k)\n","print(f\"Retrieved Chunks: {chunks}\")\n","print(f\"Retrieved Titles: {titles}\")"],"metadata":{"id":"_ElqyihrFqZY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["if chunks and titles:\n","    answer = generate_answer(query, chunks, titles,\n","                             text_generation_pipeline)\n","    print(answer)\n","else:\n","    print(\"No relevant documents found to generate an answer.\")"],"metadata":{"id":"8RU4ob-4FOLA"},"execution_count":null,"outputs":[]}]}